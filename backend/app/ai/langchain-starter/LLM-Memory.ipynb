{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello there!\n"
     ]
    }
   ],
   "source": [
    "# Have a conversational flow to manage memory\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read the local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY'] # this is now the API key to use\n",
    "\n",
    "testEnvString = os.environ['TEST_ENV'] # test to see if .env is working\n",
    "print(testEnvString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we're having LangChain try and mimic a chatbot conversation\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "llm_model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True # verbose will give you a bit more context into what the system is thinking. if you just want the output itself, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, can you help me generate test problems?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'd be happy to help you generate test problems. What subject or topic are you focusing on? For example, are you looking for math problems, science questions, language exercises, or something else? Let me know so I can tailor the problems to your needs!\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a CONVERSATION CHAIN! Chain will come later\n",
    "conversation.predict(input=\"Hello, can you help me generate test problems?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, can you help me generate test problems?\n",
      "AI: Hello! I'd be happy to help you generate test problems. What subject or topic are you focusing on? For example, are you looking for math problems, science questions, language exercises, or something else? Let me know so I can tailor the problems to your needs!\n",
      "Human: What's 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"1+1 is 2! That's a classic example of a basic arithmetic problem. If you're looking for more math problems, I can certainly help with that. Would you like problems in addition, subtraction, multiplication, division, or perhaps something more advanced like algebra or geometry? Let me know!\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What's 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, can you help me generate test problems?\n",
      "AI: Hello! I'd be happy to help you generate test problems. What subject or topic are you focusing on? For example, are you looking for math problems, science questions, language exercises, or something else? Let me know so I can tailor the problems to your needs!\n",
      "Human: What's 1+1?\n",
      "AI: 1+1 is 2! That's a classic example of a basic arithmetic problem. If you're looking for more math problems, I can certainly help with that. Would you like problems in addition, subtraction, multiplication, division, or perhaps something more advanced like algebra or geometry? Let me know!\n",
      "Human: What did I ask you to generate earlier?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You asked me to help you generate test problems. If you have a specific subject or type of problem in mind, please let me know, and I can create some tailored examples for you!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What did I ask you to generate earlier?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, can you help me generate test problems?\n",
      "AI: Hello! I'd be happy to help you generate test problems. What subject or topic are you focusing on? For example, are you looking for math problems, science questions, language exercises, or something else? Let me know so I can tailor the problems to your needs!\n",
      "Human: What's 1+1?\n",
      "AI: 1+1 is 2! That's a classic example of a basic arithmetic problem. If you're looking for more math problems, I can certainly help with that. Would you like problems in addition, subtraction, multiplication, division, or perhaps something more advanced like algebra or geometry? Let me know!\n",
      "Human: What did I ask you to generate earlier?\n",
      "AI: You asked me to help you generate test problems. If you have a specific subject or type of problem in mind, please let me know, and I can create some tailored examples for you!\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer) # this allows us to store the entire conversation, so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello, can you help me generate test problems?\\nAI: Hello! I'd be happy to help you generate test problems. What subject or topic are you focusing on? For example, are you looking for math problems, science questions, language exercises, or something else? Let me know so I can tailor the problems to your needs!\\nHuman: What's 1+1?\\nAI: 1+1 is 2! That's a classic example of a basic arithmetic problem. If you're looking for more math problems, I can certainly help with that. Would you like problems in addition, subtraction, multiplication, division, or perhaps something more advanced like algebra or geometry? Let me know!\\nHuman: What did I ask you to generate earlier?\\nAI: You asked me to help you generate test problems. If you have a specific subject or type of problem in mind, please let me know, and I can create some tailored examples for you!\"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({}) # Returns the actual object to see the entire conversation so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi\\nAI: Wazzzzzapppppp'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also set memory\n",
    "memoryNew = ConversationBufferMemory()\n",
    "memoryNew.save_context({\"input\": \"Hi\"}, {\"output\": \"Wazzzzzapppppp\"})\n",
    "\n",
    "memoryNew.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and mentions they are just hanging out. The AI responds casually, and the human asks what is on the schedule for today.\n",
      "AI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI and mentions they are just hanging out. The AI responds casually, and the human asks what is on the schedule for today. The AI outlines a busy schedule including a meeting at 8am, time to work on a LangChain project, and a lunch meeting with a customer to discuss the latest in AI. The human asks for a good demo to show, and the AI suggests several ideas including text generation, question answering, summarization, translation, sentiment analysis, code generation, and an interactive chatbot. The AI also advises tailoring the demo to the customer's specific interests and ensuring all necessary preparations are made for a smooth presentation.\"}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To add more memory, you can keep on adding and appending NEW stuff in it with save_context\n",
    "# For LLM chat conversation, the LLM is stateless and it doesn't remember anything\n",
    "\n",
    "# Usually, wrapper code is provided so the memory can provide context to each INDEPENDENT call. this is usually considered a preamble\n",
    "\n",
    "# LangChain provides good way to store different kinds of memories\n",
    "\n",
    "# BUFFERWINDOW memory: it only remembers the last x conversations (only keeps a window of memories)\n",
    "\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "# ^ with this, you can do this to prevent the memory going way too long\n",
    "# this bufferwindow memory can help save TOKENS (save money!)\n",
    "\n",
    "from langchain.memory import ConversationTokenBufferMemory # we can also use this one, to include a max token limit to save on cost and keep cost consistent\n",
    "\n",
    "# we can also have memory to SUMMARIZE the current memory conversation for us!\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"What would be a good demo to show?\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional memory types\n",
    "# Vector data memory: Stores text (from conversation or elsewhere) in a vector database, retrieve most relevant blocks of text\n",
    "\n",
    "# Entity memories\n",
    "# Using LLM, remember details about specific entities.\n",
    "# This is when you want it to remember details and facts about a certain person, etc.\n",
    "\n",
    "# You can use several different kinds of memory here in LangChain as well. You can also just store the whole conversation here too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
