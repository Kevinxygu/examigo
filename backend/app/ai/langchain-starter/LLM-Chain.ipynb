{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello there!\n"
     ]
    }
   ],
   "source": [
    "# CHAINS! It usually combines LLM with prompts, and with this you can really use this to generate a great SEQUENCE OF EVENTS TOGETHER!\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read the local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY'] # this is now the API key to use\n",
    "\n",
    "testEnvString = os.environ['TEST_ENV'] # test to see if .env is working\n",
    "print(testEnvString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can read several different kinds of inputs here!\n",
    "# For example, let's load in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./assets/TopicsList.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Let's input a few things\n",
    "# model\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "# prompts\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# chains\n",
    "from langchain.chains import LLMChain\n",
    "model = 'gpt-4o'\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1, model=model) # initialize our LLM\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best topic to study, if I want to brush up on {studyTopic}?\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to brush up on string manipulation and concatenation, focusing on the following topics can be very beneficial:\n",
      "\n",
      "1. **Basic String Operations**:\n",
      "   - Understanding string literals, escape sequences, and raw strings.\n",
      "   - Basic operations like slicing, indexing, and length calculation.\n",
      "\n",
      "2. **String Concatenation**:\n",
      "   - Using the `+` operator.\n",
      "   - Using the `join()` method.\n",
      "   - Using formatted string literals (f-strings in Python).\n",
      "   - Using the `format()` method.\n",
      "\n",
      "3. **String Methods**:\n",
      "   - Common methods like `upper()`, `lower()`, `strip()`, `replace()`, `split()`, and `find()`.\n",
      "   - Advanced methods like `partition()`, `rpartition()`, `splitlines()`, and `zfill()`.\n",
      "\n",
      "4. **Regular Expressions**:\n",
      "   - Basics of regex syntax.\n",
      "   - Using regex for pattern matching, searching, and replacing.\n",
      "\n",
      "5. **String Formatting**:\n",
      "   - Old-style formatting using `%`.\n",
      "   - New-style formatting using `str.format()`.\n",
      "   - f-strings (formatted string literals) for concise and readable formatting.\n",
      "\n",
      "6. **Unicode and Encoding**:\n",
      "   - Understanding Unicode and character encoding.\n",
      "   - Handling different encodings and decoding strings.\n",
      "\n",
      "7. **Performance Considerations**:\n",
      "   - Efficient string concatenation techniques.\n",
      "   - Understanding the performance implications of different methods.\n",
      "\n",
      "8. **Practical Applications**:\n",
      "   - Parsing and processing text files.\n",
      "   - Building and manipulating URLs.\n",
      "   - Generating dynamic content for web pages or reports.\n",
      "\n",
      "By studying these topics, you'll gain a comprehensive understanding of string manipulation and concatenation, which are fundamental skills in many programming tasks.\n"
     ]
    }
   ],
   "source": [
    "studyTopic = \"string manipulation and concatenation\"\n",
    "print(chain.run(studyTopic))\n",
    "\n",
    "# LLM chain is quite useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQUENTIAL CHAINS\n",
    "# Chains that run one after each other. The idea is to combine multiple chains where the output of one chain, is the input of the next\n",
    "\n",
    "# TWO TYPES:\n",
    "# 1. SimpleSequentialChain: single input/output\n",
    "# 2. SequentialChain: multiple inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.8, model=model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mChoosing a name for a company that makes soap with an Aloe scent involves balancing creativity, clarity, and branding appeal. Here are a few suggestions that might resonate:\n",
      "\n",
      "1. **Aloe Essence Soaps**\n",
      "2. **AloeAura**\n",
      "3. **SoothingAloe**\n",
      "4. **PureAloe Lathers**\n",
      "5. **AloeFresh Suds**\n",
      "6. **AloeDream Soaps**\n",
      "7. **AloeZen Soapworks**\n",
      "8. **AloeCrÃ¨me Creations**\n",
      "9. **AloeLux Lathers**\n",
      "10. **AloeSoothe Soaps**\n",
      "\n",
      "These names convey the key ingredient (Aloe) and evoke the soothing, natural qualities associated with aloe-scented products. Make sure to check for availability and any trademark issues before finalizing your choice.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mA company crafting Aloe-scented soaps, offering soothing and natural skincare solutions. Names include Aloe Essence Soaps, AloeAura, and SoothingAloe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A company crafting Aloe-scented soaps, offering soothing and natural skincare solutions. Names include Aloe Essence Soaps, AloeAura, and SoothingAloe.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run these in conjunction with another to make one input another, make one output inform another input, etc. etc.\n",
    "product = \"soap that smells like Aloe?\"\n",
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE INPUTS? MULTIPLE OUTPUTS?\n",
    "# we can use the regular SequentialChain for this part\n",
    "from langchain.chains import SequentialChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentially, each LLMChain is like a \"node\" along the chain, and can produce an output_key that must be EXACTLY THAT in the next chain node\n",
    "# The essential parts for each LLMChain are:\n",
    "\n",
    "# 1. need llm=llm, to note which model to use\n",
    "# 2. need prompt=prompt, can be created from template\n",
    "# 3. recommend output_key, so that the input can be used in a subsequent chain\n",
    "\n",
    "# SEVERAL DIFFERENT INPUTS can be used to create a bunch of these LLM calls! :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUTER CHAINS <- this might be super relevant to you\n",
    "\n",
    "# this is a way to route and find the best chain, based off of the input\n",
    "# The router chain can choose the best CHAIN to go down!\n",
    "\n",
    "# for example, each kind of chain can be optimized based on different topics\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific type of chain to navigate multiple prompt templates\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "# this is uses the LLM itself to choose the right chain. the output parser also \n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=model)\n",
    "\n",
    "# prompt_info is used to choose the different potential chains to use\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    # you essentially create a chain element, to start each branching path\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # then, you add it to the list/hashmap of potential destination chains the router can go anywhere\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'What is the best data structure if I want to implement a way to always have the smallest value handy and accessible?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The best data structure for always having the smallest value handy and accessible is a **Min-Heap** (also known as a Min-Priority Queue).\\n\\n### Why Min-Heap?\\n\\n1. **Efficient Access to Minimum Element**: In a Min-Heap, the smallest element is always at the root of the heap, which allows for O(1) time complexity to access the minimum element.\\n\\n2. **Efficient Insertion and Deletion**: Inserting a new element and deleting the minimum element (which is at the root) both have a time complexity of O(log n), where n is the number of elements in the heap. This is because the heap maintains a balanced binary tree structure.\\n\\n3. **Space Complexity**: The space complexity of a Min-Heap is O(n), where n is the number of elements in the heap. This is efficient and manageable for most applications.\\n\\n### How to Implement a Min-Heap\\n\\nHere is a simple implementation of a Min-Heap in Python:\\n\\n```python\\nclass MinHeap:\\n    def __init__(self):\\n        self.heap = []\\n\\n    def get_min(self):\\n        if not self.heap:\\n            return None\\n        return self.heap[0]\\n\\n    def insert(self, val):\\n        self.heap.append(val)\\n        self._heapify_up(len(self.heap) - 1)\\n\\n    def extract_min(self):\\n        if len(self.heap) == 0:\\n            return None\\n        if len(self.heap) == 1:\\n            return self.heap.pop()\\n        root = self.heap[0]\\n        self.heap[0] = self.heap.pop()\\n        self._heapify_down(0)\\n        return root\\n\\n    def _heapify_up(self, index):\\n        parent_index = (index - 1) // 2\\n        if index > 0 and self.heap[index] < self.heap[parent_index]:\\n            self.heap[index], self.heap[parent_index] = self.heap[parent_index], self.heap[index]\\n            self._heapify_up(parent_index)\\n\\n    def _heapify_down(self, index):\\n        smallest = index\\n        left_child_index = 2 * index + 1\\n        right_child_index = 2 * index + 2\\n\\n        if left_child_index < len(self.heap) and self.heap[left_child_index] < self.heap[smallest]:\\n            smallest = left_child_index\\n\\n        if right_child_index < len(self.heap) and self.heap[right_child_index] < self.heap[smallest]:\\n            smallest = right_child_index\\n\\n        if smallest != index:\\n            self.heap[index], self.heap[smallest] = self.heap[smallest], self.heap[index]\\n            self._heapify_down(smallest)\\n\\n# Example usage:\\nmin_heap = MinHeap()\\nmin_heap.insert(3)\\nmin_heap.insert(1)\\nmin_heap.insert(6)\\nmin_heap.insert(5)\\nmin_heap.insert(2)\\nmin_heap.insert(4)\\n\\nprint(min_heap.get_min())  # Output: 1\\nprint(min_heap.extract_min())  # Output: 1\\nprint(min_heap.get_min())  # Output: 2\\n```\\n\\n### Summary\\n\\nA Min-Heap is an excellent choice for a data structure when you need to frequently access the smallest element efficiently. It provides a good balance between time complexity for insertion, deletion, and access operations, and it is space-efficient.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is the best data structure if I want to implement a way to always have the smallest value handy and accessible?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is the Pythagorean theorem?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Thank you for the kind words! Let's break down the Pythagorean theorem step by step.\\n\\n### Definition:\\nThe Pythagorean theorem is a fundamental principle in geometry, specifically in the context of right-angled triangles. It states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides.\\n\\n### Mathematical Formulation:\\nIf we denote the lengths of the sides of a right-angled triangle as follows:\\n- \\\\( a \\\\) and \\\\( b \\\\) are the lengths of the two legs (the sides that form the right angle),\\n- \\\\( c \\\\) is the length of the hypotenuse,\\n\\nthen the Pythagorean theorem can be written as:\\n\\\\[ c^2 = a^2 + b^2 \\\\]\\n\\n### Breaking it Down:\\n1. **Identify the Right-Angled Triangle**: Ensure that the triangle in question has one angle that is exactly 90 degrees.\\n2. **Label the Sides**:\\n   - The side opposite the right angle is the hypotenuse (\\\\( c \\\\)).\\n   - The other two sides are the legs (\\\\( a \\\\) and \\\\( b \\\\)).\\n3. **Apply the Theorem**: Use the formula \\\\( c^2 = a^2 + b^2 \\\\) to relate the lengths of the sides.\\n\\n### Example Problem:\\nSuppose you have a right-angled triangle where one leg is 3 units long and the other leg is 4 units long. To find the length of the hypotenuse (\\\\( c \\\\)):\\n\\n1. **Identify the lengths of the legs**: \\\\( a = 3 \\\\) and \\\\( b = 4 \\\\).\\n2. **Apply the Pythagorean theorem**:\\n   \\\\[ c^2 = a^2 + b^2 \\\\]\\n   \\\\[ c^2 = 3^2 + 4^2 \\\\]\\n   \\\\[ c^2 = 9 + 16 \\\\]\\n   \\\\[ c^2 = 25 \\\\]\\n3. **Solve for \\\\( c \\\\)**:\\n   \\\\[ c = \\\\sqrt{25} \\\\]\\n   \\\\[ c = 5 \\\\]\\n\\nSo, the length of the hypotenuse is 5 units.\\n\\n### Applications:\\nThe Pythagorean theorem is widely used in various fields such as architecture, engineering, physics, and computer science. It helps in determining distances, designing structures, and solving problems involving right-angled triangles.\\n\\nI hope this breakdown helps you understand the Pythagorean theorem better! If you have any more questions or need further clarification, feel free to ask.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(chain.run(\"What is the pythagorean theorem?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
